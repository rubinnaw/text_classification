{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ims2DNWoKHeS"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import string\n",
        "import gdown\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModelForSequenceClassification, AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Rq06iaHSKMUQ",
        "outputId": "2f90a41e-435a-4f30-dab8-7e502239fcd7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'archive 39.zip'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gdown.download('https://drive.google.com/uc?export=download&id=18CHnzLHkElW707W4cvqeETe_kCveugN1', None, quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6cGjmHlLjEa"
      },
      "outputs": [],
      "source": [
        "!unzip -qo \"archive 39.zip\" -d ./data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV3_3SlBMLrU",
        "outputId": "a68f1b20-28e7-4b15-f082-047fdb0c9ee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 38740 entries, 0 to 38739\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   oid       38740 non-null  int64 \n",
            " 1   category  38740 non-null  object\n",
            " 2   text      38740 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 908.1+ KB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(         oid      category                                               text\n",
              " 0  365271984  winter_sport  Волшебные фото Виктория Поплавская ЕвгенияМедв...\n",
              " 1  503385563       extreme  Возвращение в подземелье Треша 33 Эйфория тупо...\n",
              " 2  146016084      football  Лучшие чешские вратари – Доминик Доминатор Гаш...\n",
              " 3  933865449    boardgames  Rtokenoid Warhammer40k валрак решил нас подкор...\n",
              " 4  713550145        hockey  Шестеркин затаскивает Рейнджерс в финал Восточ...,\n",
              " None)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data = pd.read_csv(\"/content/data/train.csv\")\n",
        "test_data = pd.read_csv(\"/content/data/test.csv\")\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "train_data.head(), train_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5Yl4n_Oleze",
        "outputId": "e5c33686-1ee4-4d60-decb-7ab9bdc9bcd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 35745 entries, 0 to 38739\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   oid       35745 non-null  int64 \n",
            " 1   category  35745 non-null  object\n",
            " 2   text      35745 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    return text\n",
        "\n",
        "train_data['text'] = train_data['text'].apply(preprocess_text)\n",
        "\n",
        "train_data = train_data.drop_duplicates(subset=['text'])\n",
        "\n",
        "train_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a01SwbzilpQl",
        "outputId": "ccc337a9-48d2-43af-d278-550f6703243b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28596, 7149)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train_data['text'], train_data['category'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "len(train_texts), len(val_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1unqhIZmDtF",
        "outputId": "e2d8ef31-60c3-41dd-b53e-5c8f2f481b90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13,\n",
              " {'winter_sport': 0,\n",
              "  'extreme': 1,\n",
              "  'football': 2,\n",
              "  'boardgames': 3,\n",
              "  'hockey': 4,\n",
              "  'esport': 5,\n",
              "  'athletics': 6,\n",
              "  'motosport': 7,\n",
              "  'basketball': 8,\n",
              "  'tennis': 9,\n",
              "  'autosport': 10,\n",
              "  'martial_arts': 11,\n",
              "  'volleyball': 12})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
        "\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=512)\n",
        "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=512)\n",
        "\n",
        "label_to_id = {label: idx for idx, label in enumerate(train_data['category'].unique())}\n",
        "train_labels = [label_to_id[label] for label in train_labels]\n",
        "val_labels = [label_to_id[label] for label in val_labels]\n",
        "\n",
        "len(label_to_id), label_to_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMgXcOujmKv1"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cobU56gunWAw"
      },
      "outputs": [],
      "source": [
        "train_dataset = TextDataset(train_encodings, train_labels)\n",
        "val_dataset = TextDataset(val_encodings, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCMOjBuEnX6T",
        "outputId": "882534a5-ad45-4563-8641-bbb8cf1708a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"DeepPavlov/rubert-base-cased\",\n",
        "    num_labels=len(label_to_id)\n",
        ")\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WsJ2uEDKnmXE",
        "outputId": "c1ca49d6-6ec6-41a4-e2b8-b6092bc339ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTV4pCsKnr_F",
        "outputId": "91caa7af-4ceb-4dd3-e0b9-ca11396a68b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4, Loss: 0.8422\n",
            "Epoch 2/4, Loss: 0.3940\n",
            "Epoch 3/4, Loss: 0.2378\n",
            "Epoch 4/4, Loss: 0.1569\n"
          ]
        }
      ],
      "source": [
        "epochs = 4\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nB5m0W0G3kMx",
        "outputId": "33a7897e-c222-4d73-9ec1-0f59b06dcf8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./fine_tuned_rubert/tokenizer_config.json',\n",
              " './fine_tuned_rubert/special_tokens_map.json',\n",
              " './fine_tuned_rubert/vocab.txt',\n",
              " './fine_tuned_rubert/added_tokens.json',\n",
              " './fine_tuned_rubert/tokenizer.json')"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"./fine_tuned_rubert\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_rubert\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kPIWL8H3mEu"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_combined(model, data_loader, device, id_to_label, max_examples=10):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    example_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            for text_id, pred in zip(batch['input_ids'], predictions):\n",
        "                if example_count < max_examples:\n",
        "                    text = tokenizer.decode(text_id, skip_special_tokens=True)\n",
        "                    predicted_label = id_to_label[pred.item()]\n",
        "                    print(f\"Text: {text}\\nPredicted Category: {predicted_label}\\n\")\n",
        "                    example_count += 1\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qftfq-Zo3noG",
        "outputId": "08e82af7-bc3e-498c-fd28-ea2f7b212ade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: кристиан хорнер макс ошибся у серхио была проблема с двигателем руководитель red btokenoid ratokenoid кристиан хорнер доволен результатами квалификации гран при австралии с учетом того что макс ферстаппен и серхио перес столкнулись с проблемами в финальном сегменте я очень доволен вторым и третьим местом на стартовой решетке результаты очень плотные и в разные моменты квалификации мне казалось что и макс и чеко могут выиграть поул – сказал хорнер в интервью sky sports хорнер объяснил что ферстаппену поула стоила ошибка – на своем самом быстром круге голландец заблокировал шины перес в свою очередь столкнулся с кратковременной потерей мощности силовой установки блокировка стоила максу около трех десятых секунды без нее он был бы очень очень близко ко времени шарля в первой попытке у чеко была небольшая потеря мощности к тому же у него в баке была лишняя десятая часть топлива потому что он хотел проехать три круга шарль проехал отличный круг но знаете ли мы все еще в первом и втором ряду 33\n",
            "Predicted Category: autosport\n",
            "\n",
            "Text: он будет делать нас только лучше на тренировках он был великолепен хороший лидер он не будет прятаться в углу кавай леонард о джоне уолле\n",
            "Predicted Category: basketball\n",
            "\n",
            "Text: клубы кхл ак барс и нефтехимик прокомментировали выступления членов команды россии камилы валиевой и данила садреева на олимпиаде 2022\n",
            "Predicted Category: hockey\n",
            "\n",
            "Text: на прошедшей неделе нельзя не отметить левый снизу которым турман эффективно заканчивал атаки в бою с бариосом\n",
            "Predicted Category: martial_arts\n",
            "\n",
            "Text: звездный защитник нетс джеймс харден пропустит матч с селтикс который состоится во вторник харден не сыграет в третий раз подряд из за повреждения подколенного сухожилия левой ноги у нетс 29 24 на данный момент серия из восьми поражений команда также не сможет рассчитывать на травмированного кевина дюрэнта и кайри ирвинга который не имеет права выступать в домашних встречах из за отказа от вакцинации у бостона 30 25 серия из пяти побед\n",
            "Predicted Category: basketball\n",
            "\n",
            "Text: ближайшие номерные турниры ufc 20 августа усман vs эдвардс 2 ufc278 10 сентября чимаев vs диаз ufc279 22 октября оливейра vs махачев ufc280 12 ноября адесанья vs перейра ufc281\n",
            "Predicted Category: martial_arts\n",
            "\n",
            "Text: девушки фу одна секунда это очень мало ты ничтожество парни\n",
            "Predicted Category: extreme\n",
            "\n",
            "Text: ты должен быть на высоте весь зазед мы просто не контролировали гонку когда казалась что у нас был контроль над ней с каждым коушеном мы просто продолжали терять несколько мест так оно и есть но спасибо крису гейбхарту всей команде за то что дали мне сегодня быструю машину это было невероятно когда она ехала по внешней траектории поздравляю кристофера белла эти ребята просто проделали потрясающую работу действительно извлекая выгоду и преуспевая выигрывая гонки когда это было необходимо надеюсь они смогут нести знамя joegtokenoid очевидно я пытался тоже попасть туда но это гонки это то что называют мартинсвиллом на самом деле я очень доволен тем насколько чисто проходил заезд несмотря на разнообразие машин с разными стратегиями и общим бзумством не могу выразить достаточную благодарность за то что моя команда дала нам шанс большую часть сезона мы были на 20 м месте по набранным очкам из за наших качелей в итоге мы окажемся пятыми по очкам вот что это такое отличный ход от росса честейна блестяще конечно дико но логично когда у вас нет другого выбора это конечно легко сделать но хорошо исполнено дэнни хэмлин о том как проходила борьба в гонке nascartokenoid nascar dennyhamtokenoid\n",
            "Predicted Category: autosport\n",
            "\n",
            "Text: какая из двух диагональных по вашему мнению лучше кстати они скоро будут конкурировать за место турецкой в сборной\n",
            "Predicted Category: volleyball\n",
            "\n",
            "Text: судьи видели что холм просто пыталась мешать мне драться\n",
            "Predicted Category: martial_arts\n",
            "\n",
            "Accuracy: 0.8737\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8736886277801091"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_model_combined(model, val_loader, device, {v: k for k, v in label_to_id.items()}, max_examples=10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
